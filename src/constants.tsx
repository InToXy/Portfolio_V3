
import { Highlighter } from './components/ui/highlighter';
import { Project, SkillCategory, Experience, Education, Passion, SocialLink, Certification } from './types';

// Common Data (Non-translatable or shared)
export const SOCIALS: SocialLink[] = [
  { name: "GitHub", url: "https://github.com/InToXy", icon: "github" },
  { name: "LinkedIn", url: "https://www.linkedin.com/in/matheo-pinget-8a60252a9/", icon: "linkedin" },
];

export const CALENDAR_URL = "https://cal.com/matheo-pinget-xadubu";
export const CREDLY_URL = "https://www.credly.com/users/matheo-pinget";

export const CERTIFICATIONS: Certification[] = [
  {
    name: "Microsoft Certified: Azure Fundamentals (AZ-900)",
    issuer: "Microsoft",
    date: "2024",
    badgeUrl: "https://training.cellenza.com/wp-content/uploads/2021/08/AZ900.png"
  },
  {
    name: "AWS Certified Cloud Practitioner",
    issuer: "Amazon Web Services",
    date: "2024",
    badgeUrl: "https://d1.awsstatic.com/training-and-certification/certification-badges/AWS-Certified-Cloud-Practitioner_badge.634f8a21af2e0e956ed8905a72366146ba22b74c.png"
  }
];

const SKILLS_DATA: SkillCategory[] = [
  {
    title: "CI/CD & Automation",
    skills: ["GitLab CI", "Bash", "PowerShell", "Git", "GitHub"]
  },
  {
    title: "Network",
    skills: ["Cisco", "pfSense", "WatchGuard", "Firewall"]
  },
  {
    title: "DevOps & Cloud",
    skills: ["Docker", "Terraform", "Ansible", "Azure", "AWS", "VCD", "Traefik Proxy"]
  },
  {
    title: "Programming",
    skills: ["Python", "Node.js", "API REST", "JWT", "SQL", "HTML", "CSS", "Next.js"]
  },
  {
    title: "Monitoring",
    skills: ["Prometheus", "Grafana", "Zabbix", "Centreon", "PRTG"]
  },
  {
    title: "System Admin",
    skills: ["Linux", "Windows Server", "Active Directory", "Bind", "Debian", "Ubuntu", "CentOS"]
  },
  {
    title: "Security",
    skills: ["Hardening", "Security Audit", "Fail2Ban", "CrowdSec"]
  },
  {
    title: "Project Management",
    skills: ["Agile Methods", "Scrum", "JIRA"]
  }
];

// Content Dictionary
export const TRANSLATIONS = {
  fr: {
    nav: {
      about: '√Ä Propos',
      terminal: 'Terminal',
      skills: 'Comp√©tences',
      projects: 'Projets',
      experience: 'Parcours',
      cv: 'CV',
      contact: 'Contact'
    },
    hero: {
      available: 'Disponible pour opportunit√©s',
      greeting: 'Bonjour, je suis',
      role: 'Ing√©nieur DevOps',
      subtitle: 'Ing√©nieur DevOps Cloud',
      rotating_text: ["Randonneur", "Motard", "Voyageur"],
      description: 'Je construis des solutions performantes et s√©curis√©es avec Terraform, Ansible, Docker et GitLab CI.',
      cta_contact: 'Me Contacter',
      cta_calendar: 'Prendre RDV',
      cta_cv: 'Mon CV',
      cta_certs: 'Certifications',
      location: 'Evian-les-Bains, France'
    },
    about: {
      title: '√Ä PROPOS',
      subtitle: 'Qui suis-je ?',
      description: (
        <>
          <Highlighter action="highlight" color="#87CEFA" isView={true} delay={500}>Ing√©nieur DevOps en alternance</Highlighter>, sp√©cialis√© en automatisation d'infrastructures et CI/CD.<br />
          Ma√Ætrise de Terraform, Ansible, Docker, GitLab CI.<br />
          Exp√©rience en r√©seaux, cybers√©curit√© et supervision (Prometheus, Grafana, Zabbix).<br />
          <Highlighter action="underline" color="#FF9800" isView={true} delay={1000}>Motiv√© et rigoureux</Highlighter>, je souhaite contribuer √† des <Highlighter action="underline" color="#FF9800" isView={true} delay={1500}>projets cloud performants et s√©curis√©s</Highlighter>.
        </>
      ),
      cards: {
        infra: { title: 'Infrastructure', desc: "Conception d'architectures Cloud r√©silientes et performantes." },
        collab: { title: 'Collaboration', desc: "Travail en √©quipe et m√©thodes Agiles pour une livraison continue." },
        security: { title: 'S√©curit√©', desc: "Int√©gration de la s√©curit√© d√®s la conception (DevSecOps)." }
      }
    },
    skills: {
      tag: '<Expertise />',
      title: 'Comp√©tences Techniques',
      categories: SKILLS_DATA // Using same skills for now, titles could be translated if needed but keys are English-ish
    },
    projects: {
      tag: 'Portfolio',
      title: 'Projets & R√©alisations',
      all: 'Tout',

      details: 'D√©tails',
      context: 'Contexte',
      objective: 'Objectif',
      features: 'Fonctionnalit√©s Cl√©s',
      competencies: 'Comp√©tences D√©velopp√©es',
      stack: 'Tech Stack',
      metrics: 'Chiffres Cl√©s',
      code: 'Voir le code source',
      demo: 'Live Demo',
      viewer: 'Project_Viewer v2.4'
    },
    experience: {
      title_work: 'Exp√©rience Pro',
      title_edu: 'Formation',
      title_cert: 'Certifications',
      data: [
        {
          role: "Ing√©nieur DevOps",
          company: "Orange Business",
          period: "2024 - 2027 (Alternance)",
          description: [
            "Automatisation du d√©ploiement d'infrastructures avec Terraform et Ansible.",
            "Gestion de pipelines CI/CD avec GitLab CI et Docker.",
            "Supervision des infrastructures avec Prometheus, Grafana.",
            "D√©veloppement d'un projet Git pour automatiser la r√©cup√©ration s√©curis√©e de mots de passe dans HashiVault."
          ]
        },
        {
          role: "Technicien R√©seau",
          company: "Orange",
          period: "2022 - 2024 (Alternance)",
          description: [
            "Installation et configuration de routeurs, switches et firewalls.",
            "D√©veloppement d'un outil Python pour d√©tecter des probl√®mes sur la fibre optique.",
            "Travail en √©quipe et communication avec les clients pour r√©soudre des probl√®mes techniques."
          ]
        }
      ],
      education: [
        {
          degree: "Ing√©nierie Informatique",
          school: "CESI √âcole d'Ing√©nieurs, Lyon",
          period: "2024 - 2027"
        },
        {
          degree: "Licence R√©seaux et T√©l√©communications",
          school: "IUT1, Grenoble",
          period: "2021 - 2024"
        },
        {
          degree: "Baccalaur√©at Pro Syst√®mes Num√©riques",
          school: "Lyc√©e Saint Vincent de Paul",
          period: "2018 - 2021"
        }
      ]
    },
    passions: {
      tag: 'Loisirs',
      title: 'Passions & Int√©r√™ts',
      items: [
        {
          title: "Randonn√©e & Nature",
          emoji: "ü•æ",
          description: "Exploration des sentiers de montagne et d√©couverte de paysages naturels pour me ressourcer.",
          image: "/Portfolio_V3/images/randonee.jpg"
        },
        {
          title: "Moto & M√©canique",
          emoji: "üèçÔ∏è",
          description: "Passion pour les deux-roues, entretien m√©canique et balades sur routes sinueuses.",
          image: "/Portfolio_V3/images/moto.jpg"
        },
        {
          title: "Voyage & D√©couverte",
          emoji: "‚úàÔ∏è",
          description: "Exploration de nouvelles cultures et destinations, ouverture d'esprit √† travers les rencontres.",
          image: "/Portfolio_V3/images/voyage.jpg"
        }
      ]
    },
    terminal: {
      access: 'ACC√àS SYST√àME AUTORIS√â',
      title: 'Terminal Interactif',
      desc: 'Plongez au c≈ìur du syst√®me. Explorez mon profil, mes comp√©tences et mes projets via cette interface en ligne de commande.',
      help_cmd: 'Tapez help pour initialiser la connexion.',
      commands: {
        about: 'Informations identit√© utilisateur',
        skills: 'Scanner modules comp√©tences',
        projects: 'Requ√™te base de projets',
        experience: 'Voir logs syst√®me et parcours',
        contact: 'Ouvrir canaux communication',
        cv: 'T√©l√©charger rapport statut complet',
        clear: 'Nettoyer buffer terminal'
      }
    },
    cv: {
      tag: 'Curriculum Vitae',
      title: 'Mon Parcours en D√©tail',
      download_fr: 'T√©l√©charger (FR)',
      download_en: 'T√©l√©charger (EN)',
      print: 'Imprimer',
      sections: {
        profile: 'Profil',
        experience: 'Exp√©rience Professionnelle',
        education: 'Formation',
        skills: 'Comp√©tences',
        certifications: 'Certifications',
        languages: 'Langues',
        interests: "Centres d'int√©r√™t",
        lang_fr: 'Fran√ßais',
        lang_en: 'Anglais',
        lang_native: 'Natif',
        lang_tech: 'Technique (B2)'
      },
      back: "Retour √† l'accueil"
    },
    footer: {
      title: 'Pr√™t √† collaborer ?',
      text: 'Je suis toujours int√©ress√© par de nouveaux d√©fis techniques et des opportunit√©s de collaboration. Discutons de votre prochain projet !',
      rights: 'Tous droits r√©serv√©s.',
      made_with: 'Con√ßu avec React & Tailwind CSS'
    },
    projects_data: [
      {
        title: "Plateforme Big Data pour la Sant√©",
        category: "Projet √âcole",
        image: "/Portfolio_V3/images/big_data.jpg",
        description: "Construction d'un data warehouse pour un groupe hospitalier afin d'analyser et visualiser les donn√©es m√©dicales.",
        context: "Le projet visait √† mettre en place une plateforme Big Data compl√®te pour un groupe hospitalier (CHU) afin de cr√©er un data warehouse.",
        objective: "L'objectif √©tait d'int√©grer, stocker, analyser et visualiser des donn√©es h√©t√©rog√®nes, telles que les dossiers m√©dicaux et les flux de patients, pour en extraire des informations strat√©giques.\n\nL'architecture Data Lakehouse a √©t√© choisie pour traiter les donn√©es √† travers diff√©rentes couches de qualit√© : Bronze (donn√©es brutes), Silver (nettoy√©es) et Gold (agr√©g√©es), pr√™tes pour la business intelligence.",
        tags: ["Apache Airflow", "Apache Spark (PySpark)", "MinIO", "Apache Hive", "Trino", "Apache Superset", "Docker", "Docker Compose", "Python"],
        features: ["Int√©gration de donn√©es brutes (Bronze)", "Nettoyage et transformation (Silver)", "Agr√©gation pour l'analyse (Gold)", "Orchestration des t√¢ches avec Airflow", "Traitement distribu√© avec Spark", "Visualisation interactive avec Superset"],
        competencies: ["Architecture Data Lakehouse", "Traitement de donn√©es massives (Big Data)", "Orchestration de flux de donn√©es", "Visualisation et Business Intelligence"],
        results: ["Plateforme Big Data compl√®te", "Data warehouse fonctionnel", "Analyse et visualisation des donn√©es m√©dicales", "Architecture Lakehouse fonctionnelle"],
        featured: true,
        downloadUrl: "#",
        githubUrl: "https://github.com/InToXy/BigData",
        deliverables: [
          { label: "T√©l√©charger le Livrable 1", url: "/Portfolio_V3/files/Bigdata_Livrable1.pdf" },
          { label: "T√©l√©charger le Livrable 2", url: "/Portfolio_V3/files/Bigdata_Livrable2.pdf" }
        ]
      },
      {
        title: "JACK.CREATIVE.LAB",
        category: "Projet Perso",
        image: "/Portfolio_V3/images/jackcreativelab.png",
        description: "Cr√©ation d'une micro-entreprise sp√©cialis√©e dans la refonte de sites web pour les PME.",
        context: "Cr√©ation d'une micro-entreprise sp√©cialis√©e dans la refonte de sites web pour les PME.",
        objective: "L'objectif est de transformer la pr√©sence num√©rique des entreprises avec des designs modernes, √©l√©gants et performants. Le site vitrine a √©t√© d√©velopp√© pour pr√©senter les services, les projets et attirer des clients.",
        tags: ["React", "Next.js", "TypeScript", "Tailwind CSS", "CI/CD", "GitHub Pages", "SEO", "GDPR"],
        features: ["Design sur mesure et responsive", "Optimisation performance et SEO", "Workflow automatis√©", "Conformit√© l√©gale (RGPD)"],
        competencies: ["D√©veloppement Frontend moderne", "Strat√©gies SEO et performance web", "Gestion de projet entrepreneurial", "Conformit√© RGPD"],
        results: ["Site vitrine performant", "Pr√©sence num√©rique am√©lior√©e", "Designs modernes livr√©s"],
        featured: true,
        demoUrl: "https://jackcreativelab.github.io/jack-creative-lab-website/"
      },
      {
        title: "Serveur Multim√©dia Personnel",
        category: "Projet Perso",
        image: "/Portfolio_V3/images/serveur_multimedia_personnel.jpg",
        description: "Solution compl√®te de gestion et de diffusion de contenu multim√©dia (HomeLab).",
        context: "Ce projet consiste en la conception et le d√©ploiement d'un serveur multim√©dia personnel robuste et automatis√©, permettant de centraliser, organiser et diffuser des films, s√©ries et autres contenus.",
        objective: "L'objectif √©tait de cr√©er une infrastructure flexible et facile √† maintenir gr√¢ce √† la conteneurisation.\n\nJ'ai utilis√© Docker et Docker Compose pour orchestrer plusieurs services, chacun ayant un r√¥le sp√©cifique dans la cha√Æne de gestion multim√©dia : Plex pour la diffusion, Radarr pour la gestion des films, Jackett pour l'indexation, Transmission pour le t√©l√©chargement, et Flaresolverr pour contourner les protections anti-bot.",
        tags: ["Docker", "Docker Compose", "Plex Media Server", "Radarr", "Jackett", "Transmission", "FlareSolverr", "Linux"],
        features: ["Centralisation des films et s√©ries", "Organisation automatique des m√©dias", "Acc√®s et diffusion via Plex", "R√©cup√©ration automatis√©e de nouveaux contenus", "Indexation et m√©tadonn√©es enrichies", "Contournement des protections anti-bot (FlareSolverr)"],
        competencies: ["Ma√Ætrise de Docker et Docker Compose", "Configuration et optimisation de serveurs", "Gestion des volumes et r√©seaux Docker", "D√©pannage d'environnements conteneuris√©s"],
        results: ["Centralisation et organisation des contenus multim√©dias", "Automatisation du processus de r√©cup√©ration", "Acc√®s distant et diffusion fluide", "Architecture conteneuris√©e portable", "Optimisation des ressources et stabilit√©"],
        githubUrl: "https://github.com/InToXy/docker-media-center/tree/dev"
      },
      {
        title: "Bot Trading Automatis√©",
        category: "Projet Perso",
        image: "/Portfolio_V3/images/bot_trading.webp",
        description: "Bot de trading utilisant l'API Binance pour ex√©cuter des strat√©gies crypto.",
        context: "Cr√©ation d'un bot de trading automatis√© utilisant l'API Binance pour ex√©cuter des strat√©gies de trading sur les cryptomonnaies.",
        objective: "L'objectif √©tait de d√©velopper un syst√®me robuste capable d'analyser les donn√©es du march√© en temps r√©el et de prendre des d√©cisions d'achat ou de vente bas√©es sur des indicateurs techniques.\n\nLe projet visait √©galement √† mettre en place un syst√®me de backtesting pour √©valuer l'efficacit√© des strat√©gies sur des donn√©es historiques, ainsi qu'un dashboard de suivi des performances en temps r√©el.",
        tags: ["Python", "Binance API", "Pandas", "NumPy", "TensorFlow", "Docker", "PostgreSQL", "Grafana"],
        features: ["Strat√©gies techniques (MACD, RSI)", "Gestion des risques", "Backtesting sur donn√©es historiques", "Dashboard Grafana temps r√©el", "Optimisation des param√®tres", "Stop-loss et take-profit automatiques"],
        competencies: ["Analyse de donn√©es financi√®res avec Python", "Int√©gration d'APIs tierces", "Backtesting de strat√©gies de trading", "Visualisation de donn√©es avec Grafana"],
        results: ["D√©veloppement d'un bot de trading fonctionnel", "Int√©gration r√©ussie avec l'API Binance", "Cr√©ation d'un syst√®me de backtesting", "D√©ploiement d'un dashboard de monitoring"],
        githubUrl: "https://github.com/InToXy/Bot_Trading.git"
      },
      {
        title: "Breezy - R√©seau Social L√©ger",
        category: "Projet √âcole",
        image: "/Portfolio_V3/images/breezy.png",
        description: "R√©seau social l√©ger inspir√© de Twitter/X, optimis√© pour faibles ressources.",
        context: "D√©veloppement d'un r√©seau social l√©ger et r√©actif, inspir√© de Twitter/X, con√ßu pour fonctionner efficacement dans des environnements √† faibles ressources et avec une connectivit√© limit√©e.",
        objective: "L'objectif principal √©tait d'offrir une exp√©rience utilisateur simple et fluide permettant de publier, liker, commenter, suivre et √™tre suivi, tout en maintenant des performances optimales.\n\nBackend - Architecture Microservices :\n‚Ä¢ Services ind√©pendants : auth, users, posts, feed\n‚Ä¢ Node.js + Express pour chaque microservice\n‚Ä¢ MongoDB avec Mongoose pour la persistance\n‚Ä¢ Authentification JWT avec refresh tokens\n‚Ä¢ Traefik comme API Gateway et Load Balancer",
        tags: ["Node.js", "Express", "MongoDB", "React", "Next.js", "TailwindCSS", "Docker", "Traefik", "JWT", "Microservices"],
        features: ["Messages courts (280 caract√®res)", "Fil d'actualit√© chronologique", "Syst√®me de commentaires et r√©ponses", "Syst√®me de likes", "Suivi d'utilisateurs", "Profils personnalis√©s avec bio"],
        competencies: ["Architecture microservices et conteneurisation", "S√©curisation avec JWT et sessions", "D√©veloppement full-stack moderne", "Int√©gration continue et DevOps"],
        results: ["R√©seau social fonctionnel et extensible", "Exp√©rience utilisateur fluide, optimis√©e mobile", "Architecture scalable et maintenable", "Pipeline CI/CD avec ESLint et Snyk"],
        downloadUrl: "#",
        githubUrl: "https://github.com/DAD-Equipe-5/Breezy",
        deliverables: [
          { label: "T√©l√©charger le Rapport", url: "/Portfolio_V3/files/breezy-rapport-soutenance.pdf" }
        ]
      },
      {
        title: "EasySave - Logiciel de Sauvegarde",
        category: "Projet √âcole",
        image: "/Portfolio_V3/images/easysave.jpg",
        description: "Logiciel de sauvegarde professionnel √©volutif d√©velopp√© en C#/.NET.",
        context: "Projet acad√©mique r√©alis√© dans le cadre d'un √©diteur logiciel fictif (ProSoft), visant √† d√©velopper un logiciel de sauvegarde performant et √©volutif destin√© √† des utilisateurs professionnels.",
        objective: "L'objectif √©tait de cr√©er une solution fiable et simple d'utilisation, avec de fortes attentes en termes de performance et de maintenabilit√© du code.\n\nArchitecture MVC :\n‚Ä¢ S√©paration claire Mod√®le / Vue / Contr√¥leur\n‚Ä¢ Modularit√© et maintenabilit√© du code\n‚Ä¢ √âvolutivit√© assur√©e pour les versions futures",
        tags: ["C#", ".NET 8.0", "WPF", "MVC", "SHA-256", "JSON", "Doxygen", "JIRA", "Git", "Scrum"],
        features: ["Interface graphique WPF moderne", "Sauvegardes compl√®tes ou diff√©rentielles", "Chiffrement SHA-256 int√©gr√©", "D√©tection de logiciels m√©tiers bloquants", "Sauvegardes en parall√®le", "Gestion des priorit√©s", "Console d√©port√©e (Sockets)"],
        competencies: ["D√©veloppement C#/.NET avanc√©", "Architecture logicielle MVC", "Gestion de projet agile (Scrum)", "Versioning Git et workflow collaboratif"],
        results: ["Logiciel modulaire et maintenable livr√©", "√âvolutivit√© prouv√©e sur 3 versions majeures", "Interface utilisateur intuitive et professionnelle", "Performance optimis√©e avec sauvegardes parall√®les"],
        downloadUrl: "#",
        githubUrl: "https://github.com/InToXy/EasySave",
        deliverables: [
          { label: "T√©l√©charger le Rapport", url: "/Portfolio_V3/files/easysave-rapport.pdf" },
          { label: "T√©l√©charger le Diaporama", url: "/Portfolio_V3/files/easysave-diapo.pdf" }
        ]
      },
      {
        title: "Gestion S√©curis√©e des Mots de Passe",
        category: "Projet Pro",
        image: "/Portfolio_V3/images/password_vault.png",
        description: "Solution DevSecOps automatis√©e pour la gestion de mots de passe d'infrastructure.",
        context: "D√©veloppement d'une solution automatis√©e et s√©curis√©e pour g√©rer les mots de passe d'infrastructure dans une d√©marche DevSecOps chez Orange Business.",
        objective: "Constat Initial : Transmission manuelle des mots de passe (risques), processus lent, manque de tra√ßabilit√©, co√ªts √©lev√©s.\n\nPipeline CI/CD D√©velopp√© :\n1. retrieve_password : R√©cup√©ration s√©curis√©e depuis HashiCorp Vault\n2. check_delete : V√©rification automatique avant suppression\n3. confirm_delete : Suppression valid√©e manuellement",
        tags: ["HashiCorp Vault", "Ansible", "GitLab CI/CD", "OpenSSL", "AES-256", "WSL", "DevSecOps", "Automation"],
        features: ["R√©cup√©ration automatis√©e des mots de passe", "Suppression s√©curis√©e et contr√¥l√©e", "Chiffrement AES-256 des transferts", "Tra√ßabilit√© compl√®te (logs)", "Validation manuelle des suppressions"],
        competencies: ["Conception de r√¥les Ansible modulaires", "Int√©gration de la s√©curit√© dans CI/CD", "Exp√©rience DevOps/DevSecOps", "Gestion d'infrastructures s√©curis√©es"],
        results: ["100 machines trait√©es en moins de 5 minutes", "Automatisation compl√®te du processus", "R√©duction significative des co√ªts op√©rationnels", "Am√©lioration de la s√©curit√© et satisfaction utilisateurs"],
        downloadUrl: "#",
        githubUrl: "https://github.com/InToXy/MPI_POC_Vault_Retrieve",
        deliverables: [
          { label: "T√©l√©charger le Rapport", url: "/Portfolio_V3/files/password-management-rapport.pdf" }
        ]
      },
      {
        title: "Optimisation de Tourn√©es - ADEME",
        category: "Projet √âcole",
        image: "/Portfolio_V3/images/ademe.webp",
        description: "Projet de recherche op√©rationnelle pour r√©duire les √©missions CO‚ÇÇ des transports.",
        context: "Projet universitaire en collaboration avec l'ADEME pour √©tudier l'optimisation des tourn√©es de livraison, une variante complexe du probl√®me du Voyageur de Commerce (TSP).",
        objective: "R√©pondre √† un appel √† projet pour r√©duire la consommation √©nerg√©tique et les √©missions de CO‚ÇÇ li√©es aux transports de marchandises.\n\nM√©thodes d'Optimisation Impl√©ment√©es :\n‚Ä¢ M√©thode Exacte (PLNE)\n‚Ä¢ M√©taheuristiques Avanc√©es : Recuit Simul√©, Algorithme G√©n√©tique, Colonie de Fourmis",
        tags: ["Python", "PLNE", "Algorithmes G√©n√©tiques", "Recuit Simul√©", "Colonie de Fourmis", "Optimisation", "Recherche Op√©rationnelle"],
        features: ["Mod√©lisation en Graphe", "Prise en compte de contraintes complexes (temps, circuits)", "Comparaison syst√©matique des performances", "G√©n√©ration de matrices al√©atoires"],
        competencies: ["Mod√©lisation math√©matique (NP-difficile)", "Impl√©mentation d'algorithmes complexes", "Analyse comparative algorithmique", "Programmation Python scientifique"],
        results: ["Les heuristiques donnent des r√©sultats proches de l'optimum", "Temps de calcul drastiquement r√©duit vs m√©thode exacte", "Colonie de fourmis particuli√®rement efficace sur les grandes instances", "Algorithme g√©n√©tique excellent pour l'exploration"],
        downloadUrl: "#",
        githubUrl: "https://github.com/InToXy/Recherche-Operationnelle",
        deliverables: [
          { label: "T√©l√©charger le Diaporama", url: "/Portfolio_V3/files/route-optimization-diapo.pdf" }
        ]
      },
      {
        title: "Infrastructure Cloud avec OpenStack",
        category: "Projet √âcole",
        image: "/Portfolio_V3/images/openstack-cloud-infrastructure-dashboard-with-virt.png",
        description: "Construction d'un r√©seau informatique complet pour une petite structure.",
        context: "Ce projet consistait √† cr√©er une infrastructure cloud compl√®te pour une petite structure en utilisant OpenStack.",
        objective: "L'objectif √©tait de d√©montrer la capacit√© √† concevoir, d√©ployer et g√©rer un environnement virtualis√© professionnel.\n\nL'infrastructure incluait la mise en place de serveurs virtuels sous diff√©rents syst√®mes d'exploitation (CentOS 8, Windows 10), la configuration d'un r√©seau priv√© s√©curis√©, et l'impl√©mentation de services essentiels (Apache, MySQL, Nextcloud).",
        tags: ["OpenStack", "CentOS 8", "Windows 10", "DNS", "Apache", "MySQL", "Nextcloud", "Prometheus", "Grafana"],
        features: ["R√©seau priv√© avec DHCP/DNS", "Routage inter-r√©seaux s√©curis√©", "Gestion des utilisateurs et acc√®s", "Serveur web Apache + MySQL", "Nextcloud pour stockage collaboratif", "Monitoring complet avec alertes automatis√©es"],
        competencies: ["Administration OpenStack et virtualisation", "Configuration r√©seau avanc√©e", "D√©ploiement et gestion de services", "Monitoring et observabilit√©"],
        results: ["Infrastructure cloud compl√®te et fonctionnelle", "R√©seau priv√© s√©curis√© avec services int√©gr√©s", "Monitoring complet avec alertes automatis√©es", "Documentation technique d√©taill√©e"],
        githubUrl: "https://github.com/InToXy"
      },
      {
        title: "S√©curisation d'un Syst√®me d'Information",
        category: "Projet √âcole",
        image: "/Portfolio_V3/images/network-security-audit-dashboard-with-vulnerabilit.png",
        description: "Infrastructure d'entreprise compl√®te selon les recommandations ANSSI.",
        context: "Ce projet ambitieux consistait √† concevoir et d√©ployer une infrastructure d'entreprise compl√®te en respectant scrupuleusement les recommandations de l'ANSSI.",
        objective: "L'architecture incluait une DMZ pour isoler les services publics, un syst√®me d'information interne s√©curis√©, et plusieurs couches de protection avec des firewalls redondants.\n\nD√©fense en Profondeur :\n‚Ä¢ Multiples couches de s√©curit√© : firewalls, IDS/IPS, antivirus\n‚Ä¢ Segmentation r√©seau avec VLANs s√©curis√©s\n‚Ä¢ Contr√¥le d'acc√®s et chiffrement des donn√©es",
        tags: ["ESXI 6.7", "Cisco", "WatchGuard", "StormShield", "Veeam", "PRTG", "Splunk", "Active Directory", "BIND", "Apache"],
        features: ["DMZ avec serveurs web publics", "Firewalls WatchGuard et StormShield", "Active Directory avec GPO s√©curis√©es", "PRTG pour monitoring r√©seau", "Splunk pour analyse des logs", "Veeam pour sauvegarde centralis√©e"],
        competencies: ["Architecture de s√©curit√© d'entreprise", "Configuration de firewalls et IDS/IPS", "Gestion des identit√©s et des acc√®s", "Monitoring et analyse de s√©curit√©"],
        results: ["Infrastructure conforme aux recommandations ANSSI", "S√©curit√© multicouche avec monitoring complet", "Strat√©gie de sauvegarde 3-2-1 op√©rationnelle", "Documentation technique et proc√©dures d√©taill√©es"],
        githubUrl: "https://github.com/InToXy"
      },
      {
        title: "D√©couverte du Pentesting",
        category: "Projet √âcole",
        image: "/Portfolio_V3/images/web-application-penetration-testing-with-burp-suit.png",
        description: "Apprentissage autonome des techniques de test d'intrusion.",
        context: "Ce projet d'apprentissage autonome avait pour objectif d'acqu√©rir les bases du pentesting √©thique.",
        objective: "Il s'agissait de comprendre les m√©thodologies d'audit de s√©curit√© et de ma√Ætriser les outils essentiels utilis√©s par les professionnels de la cybers√©curit√©. Le projet incluait la r√©solution d'un questionnaire technique complexe n√©cessitant l'identification et l'exploitation de vuln√©rabilit√©s sur diff√©rents syst√®mes dans un environnement de laboratoire contr√¥l√©.",
        tags: ["Kali Linux", "Metasploit", "Nmap", "Hydra", "SQLmap", "Burp Suite", "Wireshark", "John the Ripper"],
        features: ["Reconnaissance et Exploitation (Nmap, Metasploit, Hydra)", "Analyse et Reporting (Burp Suite, SQLmap)", "Escalade de privil√®ges sur Linux et Windows", "Documentation et recommandations de rem√©diation"],
        competencies: ["Tests d'intrusion √©thiques", "Analyse de vuln√©rabilit√©s web/r√©seau", "Utilisation d'outils de s√©curit√© avanc√©s", "M√©thodologies d'audit de s√©curit√©"],
        results: ["Ma√Ætrise des outils de pentesting essentiels", "Compr√©hension des vuln√©rabilit√©s communes", "Capacit√© √† r√©diger des rapports techniques", "Sensibilisation aux aspects √©thiques et l√©gaux"],
        githubUrl: "https://github.com/InToXy"
      },
      {
        title: "Traitement de Donn√©es avec Python",
        category: "Projet √âcole",
        image: "/Portfolio_V3/images/python-data-analysis-dashboard-with-charts--graphs.png",
        description: "Analyse et visualisation de donn√©es de calendrier.",
        context: "Ce projet consistait √† d√©velopper un script Python sophistiqu√© pour analyser et traiter des donn√©es issues de fichiers de calendrier au format CSV.",
        objective: "L'objectif √©tait de cr√©er un outil capable d'extraire, filtrer et pr√©senter des informations sp√©cifiques sur les √©v√©nements et r√©unions. Le d√©fi principal √©tait de transformer des donn√©es brutes en informations exploitables, pr√©sent√©es sous forme de tableaux Markdown et de graphiques interactifs.",
        tags: ["Python", "Pandas", "Matplotlib", "CSV", "Markdown", "HTML/CSS", "Jupyter", "NumPy"],
        features: ["Parsing automatique de fichiers CSV", "Filtrage intelligent par type et date", "G√©n√©ration de graphiques Matplotlib", "Tableaux Markdown format√©s", "Export HTML/CSS personnalis√©"],
        competencies: ["Manipulation de donn√©es avec Pandas", "Visualisation avec Matplotlib", "D√©veloppement Python orient√© objet", "Tests unitaires et documentation"],
        results: ["Outil d'analyse de donn√©es complet et fonctionnel", "Visualisations graphiques claires et informatives", "Code document√© avec tests unitaires", "Interface utilisateur intuitive et robuste"],
        githubUrl: "https://github.com/InToXy"
      }
    ]
  },
  en: {
    nav: {
      about: 'About',
      terminal: 'Terminal',
      skills: 'Skills',
      projects: 'Projects',
      experience: 'Experience',
      cv: 'Resume',
      contact: 'Contact'
    },
    hero: {
      available: 'Available for opportunities',
      greeting: 'Hello, I am',
      role: 'DevOps Engineer',
      subtitle: 'Cloud DevOps Engineer',
      rotating_text: ["Hiker", "Biker", "Traveler"],
      description: 'I build performant and secure solutions with Terraform, Ansible, Docker, and GitLab CI.',
      cta_contact: 'Contact Me',
      cta_calendar: 'Book a Meeting',
      cta_cv: 'My Resume',
      cta_certs: 'Certifications',
      location: 'Evian-les-Bains, France'
    },
    about: {
      title: 'ABOUT',
      subtitle: 'Who am I?',
      description: (
        <>
          <Highlighter action="highlight" color="#87CEFA" isView={true} delay={2000}>DevOps Engineer</Highlighter> apprentice specializing in infrastructure automation and CI/CD.<br />
          Proficient in Terraform, Ansible, Docker, GitLab CI.<br />
          Experience in networking, cybersecurity, and monitoring (Prometheus, Grafana, Zabbix).<br />
          <Highlighter action="underline" color="#FF9800" isView={true} delay={2000}>Motivated and rigorous</Highlighter>, I aim to contribute to <Highlighter action="underline" color="#FF9800" isView={true} delay={2000}>performant and secure cloud projects</Highlighter>.
        </>
      ),
      cards: {
        infra: { title: 'Infrastructure', desc: "Designing resilient and performant Cloud architectures." },
        collab: { title: 'Collaboration', desc: "Teamwork and Agile methodologies for continuous delivery." },
        security: { title: 'Security', desc: "Integrating security by design (DevSecOps)." }
      }
    },
    skills: {
      tag: '<Expertise />',
      title: 'Technical Skills',
      categories: SKILLS_DATA
    },
    projects: {
      tag: 'Portfolio',
      title: 'Projects & Achievements',
      all: 'All',

      details: 'Details',
      context: 'Context',
      objective: 'Objective',
      features: 'Key Features',
      competencies: 'Key Competencies',
      stack: 'Tech Stack',
      metrics: 'Key Metrics',
      code: 'View Source',
      demo: 'Live Demo',
      viewer: 'Project_Viewer v2.4'
    },
    experience: {
      title_work: 'Work Experience',
      title_edu: 'Education',
      title_cert: 'Certifications',
      data: [
        {
          role: "DevOps Engineer",
          company: "Orange Business",
          period: "2024 - 2027 (Apprenticeship)",
          description: [
            "Automating infrastructure deployment with Terraform and Ansible.",
            "Managing CI/CD pipelines with GitLab CI and Docker.",
            "Monitoring infrastructures with Prometheus and Grafana.",
            "Developing a Git project to automate secure password retrieval in HashiVault."
          ]
        },
        {
          role: "Network Technician",
          company: "Orange",
          period: "2022 - 2024 (Apprenticeship)",
          description: [
            "Installation and configuration of routers, switches, and firewalls.",
            "Developing a Python tool to detect optical fiber issues.",
            "Teamwork and client communication for technical troubleshooting."
          ]
        }
      ],
      education: [
        {
          degree: "Computer Engineering",
          school: "CESI Engineering School, Lyon",
          period: "2024 - 2027"
        },
        {
          degree: "Bachelor in Networks & Telecoms",
          school: "IUT1, Grenoble",
          period: "2021 - 2024"
        },
        {
          degree: "Vocational Baccalaureate Digital Systems",
          school: "Lyc√©e Saint Vincent de Paul",
          period: "2018 - 2021"
        }
      ]
    },
    passions: {
      tag: 'Hobbies',
      title: 'Passions & Interests',
      items: [
        {
          title: "Hiking & Nature",
          emoji: "ü•æ",
          description: "Exploring mountain trails and discovering natural landscapes to recharge.",
          image: "/Portfolio_V3/images/randonee.jpg"
        },
        {
          title: "Motorcycles & Mechanics",
          emoji: "üèçÔ∏è",
          description: "Passion for two-wheelers, mechanical maintenance, and riding on winding roads.",
          image: "/Portfolio_V3/images/moto.jpg"
        },
        {
          title: "Travel & Discovery",
          emoji: "‚úàÔ∏è",
          description: "Exploring new cultures and destinations, opening my mind through encounters.",
          image: "/Portfolio_V3/images/voyage.jpg"
        }
      ]
    },
    terminal: {
      access: 'SYSTEM ACCESS GRANTED',
      title: 'Interactive Terminal',
      desc: 'Dive into the system. Explore my profile, skills, and projects via this command-line interface.',
      help_cmd: 'Type help to initialize connection.',
      commands: {
        about: 'User identity information',
        skills: 'Scan competence modules',
        projects: 'Query project database',
        experience: 'View system logs and career path',
        contact: 'Open communication channels',
        cv: 'Download full status report',
        clear: 'Clear terminal buffer'
      }
    },
    cv: {
      tag: 'Curriculum Vitae',
      title: 'Detailed Career Path',
      download_fr: 'Download (FR)',
      download_en: 'Download (EN)',
      print: 'Print',
      sections: {
        profile: 'Profile',
        experience: 'Work Experience',
        education: 'Education',
        skills: 'Skills',
        certifications: 'Certifications',
        languages: 'Languages',
        interests: "Interests",
        lang_fr: 'French',
        lang_en: 'English',
        lang_native: 'Native',
        lang_tech: 'Technical (B2)'
      },
      back: "Back to Home"
    },
    footer: {
      title: 'Ready to collaborate?',
      text: 'I am always interested in new technical challenges and collaboration opportunities. Let\'s discuss your next project!',
      rights: 'All rights reserved.',
      made_with: 'Designed with React & Tailwind CSS'
    },
    projects_data: [
      {
        title: "Big Data Healthcare Platform",
        category: "School Project",
        image: "/Portfolio_V3/images/big_data.jpg",
        description: "Building a data warehouse for a hospital group to analyze and visualize medical data.",
        context: "The project aimed to implement a complete Big Data platform for a hospital group (University Hospital) to create a data warehouse.",
        objective: "The objective was to integrate, store, analyze, and visualize heterogeneous data, such as medical records and patient flows, to extract strategic insights.\n\nThe Data Lakehouse architecture was chosen to process data through different quality layers: Bronze (raw data), Silver (cleaned), and Gold (aggregated), ready for Business Intelligence.",
        tags: ["Apache Airflow", "Apache Spark (PySpark)", "MinIO", "Apache Hive", "Trino", "Apache Superset", "Docker", "Docker Compose", "Python"],
        features: ["Raw data integration (Bronze)", "Cleaning and transformation (Silver)", "Aggregation for analysis (Gold)", "Task orchestration with Airflow", "Distributed processing with Spark", "Interactive visualization with Superset"],
        competencies: ["Data Lakehouse Architecture", "Big Data Processing", "Data Workflow Orchestration", "Visualization and Business Intelligence"],
        results: ["Complete Big Data Platform", "Functional Data Warehouse", "Medical Data Analysis & Viz", "Operational Lakehouse Architecture"],
        featured: true,
        downloadUrl: "#",
        githubUrl: "#",
        deliverables: [
          { label: "Download Deliverable 1", url: "/Portfolio_V3/files/Bigdata_Livrable1.pdf" },
          { label: "Download Deliverable 2", url: "/Portfolio_V3/files/Bigdata_Livrable2.pdf" }
        ]
      },
      {
        title: "JACK.CREATIVE.LAB",
        category: "Personal Project",
        image: "/Portfolio_V3/images/jackcreativelab.png",
        description: "Creation of a micro-enterprise specializing in website redesign for SMEs.",
        context: "Creation of a micro-enterprise specializing in website redesign for SMEs.",
        objective: "The goal is to transform the digital presence of businesses with modern, elegant, and high-performance designs. The showcase site was developed to present services, projects, and attract clients.",
        tags: ["React", "Next.js", "TypeScript", "Tailwind CSS", "CI/CD", "GitHub Pages", "SEO", "GDPR"],
        features: ["Custom and responsive design", "Performance and SEO optimization", "Automated workflow", "GDPR compliance"],
        competencies: ["Modern Frontend Development", "SEO & Web Performance Strategies", "Entrepreneurial Project Management", "GDPR Compliance"],
        results: ["High-performance showcase site", "Improved digital presence", "Modern designs delivered"],
        featured: true,
        demoUrl: "#"
      },
      {
        title: "Personal Media Server",
        category: "Personal Project",
        image: "/Portfolio_V3/images/serveur_multimedia_personnel.jpg",
        description: "Complete solution for managing and streaming multimedia content (HomeLab).",
        context: "This project involves designing and deploying a robust and automated personal media server to centralize, organize, and stream movies, series, and other content.",
        objective: "The goal was to create a flexible and easy-to-maintain infrastructure using containerization.\n\nI used Docker and Docker Compose to orchestrate multiple services, each playing a specific role in the media management chain: Plex for streaming, Radarr for movie management, Jackett for indexing, Transmission for downloading, and Flaresolverr to bypass anti-bot protections.",
        tags: ["Docker", "Docker Compose", "Plex Media Server", "Radarr", "Jackett", "Transmission", "FlareSolverr", "Linux"],
        features: ["Centralization of movies and series", "Automatic media organization", "Access and streaming via Plex", "Automated content retrieval", "Indexing and enriched metadata", "Anti-bot protection bypass (FlareSolverr)"],
        competencies: ["Docker & Docker Compose Mastery", "Server Configuration & Optimization", "Docker Volume & Network Management", "Containerized Environment Troubleshooting"],
        results: ["Centralized & organized media content", "Automated retrieval process", "Seamless remote access & streaming", "Portable containerized architecture", "Resource optimization & stability"],
        githubUrl: "#"
      },
      {
        title: "Automated Trading Bot",
        category: "Personal Project",
        image: "/Portfolio_V3/images/bot_trading.webp",
        description: "Trading bot using Binance API to execute crypto strategies.",
        context: "Creation of an automated trading bot using the Binance API to execute trading strategies on cryptocurrencies.",
        objective: "The objective was to develop a robust system capable of analyzing market data in real-time and making buy/sell decisions based on technical indicators.\n\nThe project also aimed to implement a backtesting system to evaluate strategy effectiveness on historical data, as well as a dashboard for real-time performance monitoring.",
        tags: ["Python", "Binance API", "Pandas", "NumPy", "TensorFlow", "Docker", "PostgreSQL", "Grafana"],
        features: ["Technical strategies (MACD, RSI)", "Risk management", "Backtesting on historical data", "Real-time Grafana dashboard", "Parameter optimization", "Automatic stop-loss and take-profit"],
        competencies: ["Financial Data Analysis with Python", "Third-party API Integration", "Trading Strategy Backtesting", "Data Visualization with Grafana"],
        results: ["Functional trading bot developed", "Successful Binance API integration", "Backtesting system created", "Monitoring dashboard deployed"],
        githubUrl: "#"
      },
      {
        title: "Breezy - Lightweight Social Network",
        category: "School Project",
        image: "/Portfolio_V3/images/breezy.png",
        description: "Lightweight social network inspired by Twitter/X, optimized for low resources.",
        context: "Development of a lightweight and responsive social network, inspired by Twitter/X, designed to run efficiently in low-resource environments with limited connectivity.",
        objective: "The main objective was to offer a simple and fluid user experience allowing posting, liking, commenting, following, and being followed, while maintaining optimal performance.\n\nBackend - Microservices Architecture:\n‚Ä¢ Independent services: auth, users, posts, feed\n‚Ä¢ Node.js + Express for each microservice\n‚Ä¢ MongoDB with Mongoose for persistence\n‚Ä¢ JWT Authentication with refresh tokens\n‚Ä¢ Traefik as API Gateway and Load Balancer",
        tags: ["Node.js", "Express", "MongoDB", "React", "Next.js", "TailwindCSS", "Docker", "Traefik", "JWT", "Microservices"],
        features: ["Short messages (280 chars)", "Chronological feed", "Comment and reply system", "Like system", "User following", "Custom profiles with bio"],
        competencies: ["Microservices Architecture & Containerization", "Security with JWT & Sessions", "Modern Full-stack Development", "CI/CD & DevOps Integration"],
        results: ["Functional and extensible social network", "Fluid user experience, mobile-optimized", "Scalable and maintainable architecture", "CI/CD Pipeline with ESLint and Snyk"],
        downloadUrl: "#",
        githubUrl: "#",
        deliverables: [
          { label: "Download Report", url: "/Portfolio_V3/files/breezy-rapport-soutenance.pdf" }
        ]
      },
      {
        title: "EasySave - Backup Software",
        category: "School Project",
        image: "/Portfolio_V3/images/easysave.jpg",
        description: "Scalable professional backup software developed in C#/.NET.",
        context: "Academic project realized for a fictitious software publisher (ProSoft), aiming to develop high-performance and scalable backup software for professional users.",
        objective: "The goal was to create a reliable and easy-to-use solution, with high expectations regarding performance and code maintainability.\n\nMVC Architecture:\n‚Ä¢ Clear Model / View / Controller separation\n‚Ä¢ Code modularity and maintainability\n‚Ä¢ Scalability ensured for future versions",
        tags: ["C#", ".NET 8.0", "WPF", "MVC", "SHA-256", "JSON", "Doxygen", "JIRA", "Git", "Scrum"],
        features: ["Modern WPF GUI", "Full or differential backups", "Integrated SHA-256 encryption", "Blocking business software detection", "Parallel backups", "Priority management", "Remote console (Sockets)"],
        competencies: ["Advanced C#/.NET Development", "MVC Software Architecture", "Agile Project Management (Scrum)", "Git Versioning & Collaborative Workflow"],
        results: ["Modular and maintainable software delivered", "Proven scalability over 3 major versions", "Intuitive and professional UI", "Optimized performance with parallel backups"],
        downloadUrl: "#",
        githubUrl: "#",
        deliverables: [
          { label: "Download Report", url: "/Portfolio_V3/files/easysave-rapport.pdf" },
          { label: "Download Slides", url: "/Portfolio_V3/files/easysave-diapo.pdf" }
        ]
      },
      {
        title: "Secure Password Management",
        category: "Professional Project",
        image: "/Portfolio_V3/images/password_vault.png",
        description: "Automated DevSecOps solution for infrastructure password management.",
        context: "Development of an automated and secure solution to manage infrastructure passwords within a DevSecOps approach at Orange Business.",
        objective: "Context and Problem:\nInitial State: Manual password transmission (risks), slow process, lack of traceability, high costs.\n\nDeveloped CI/CD Pipeline:\n1. retrieve_password: Secure retrieval from HashiCorp Vault\n2. check_delete: Automatic verification before deletion\n3. confirm_delete: Manually validated deletion",
        tags: ["HashiCorp Vault", "Ansible", "GitLab CI/CD", "OpenSSL", "AES-256", "WSL", "DevSecOps", "Automation"],
        features: ["Automated password retrieval", "Secure and controlled deletion", "AES-256 transfer encryption", "Full traceability (logs)", "Manual deletion validation"],
        competencies: ["Modular Ansible Role Design", "Security Integration in CI/CD", "DevOps/DevSecOps Experience", "Secure Infrastructure Management"],
        results: ["100 machines processed in under 5 minutes", "Complete process automation", "Significant operational cost reduction", "Improved security and user satisfaction"],
        downloadUrl: "#",
        githubUrl: "#",
        deliverables: [
          { label: "Download Report", url: "/Portfolio_V3/files/password-management-rapport.pdf" }
        ]
      },
      {
        title: "Route Optimization - ADEME",
        category: "School Project",
        image: "/Portfolio_V3/images/ademe.webp",
        description: "Operations research project to reduce CO‚ÇÇ emissions in transport.",
        context: "University project in collaboration with ADEME to study delivery route optimization, a complex variant of the Traveling Salesman Problem (TSP).",
        objective: "Responding to a call for projects to reduce energy consumption and CO‚ÇÇ emissions related to freight transport.\n\nImplemented Optimization Methods:\n‚Ä¢ Exact Method (ILP)\n‚Ä¢ Advanced Metaheuristics: Simulated Annealing, Genetic Algorithm, Ant Colony Optimization",
        tags: ["Python", "PLNE", "Algorithmes G√©n√©tiques", "Recuit Simul√©", "Colonie de Fourmis", "Optimisation", "Recherche Op√©rationnelle"],
        features: ["Graph Modeling", "Complex constraints handling (time, circuits)", "Systematic performance comparison", "Random matrix generation"],
        competencies: ["Mathematical Modeling (NP-Hard)", "Complex Algorithm Implementation", "Comparative Algorithmic Analysis", "Scientific Python Programming"],
        results: ["Heuristics provide near-optimal results", "Drastically reduced computation time vs exact method", "Ant Colony particularly effective on large instances", "Genetic Algorithm excellent for exploration"],
        downloadUrl: "#",
        githubUrl: "#",
        deliverables: [
          { label: "Download Slides", url: "/Portfolio_V3/files/route-optimization-diapo.pdf" }
        ]
      },
      {
        title: "Cloud Infrastructure with OpenStack",
        category: "School Project",
        image: "/Portfolio_V3/images/openstack-cloud-infrastructure-dashboard-with-virt.png",
        description: "Construction of a complete computer network for a small structure.",
        context: "This project consisted of creating a complete cloud infrastructure for a small structure using OpenStack.",
        objective: "The goal was to demonstrate the ability to design, deploy, and manage a professional virtualized environment.\n\nThe infrastructure included setting up virtual servers under different operating systems (CentOS 8, Windows 10), configuring a secure private network, and implementing essential services (Apache, MySQL, Nextcloud).",
        tags: ["OpenStack", "CentOS 8", "Windows 10", "DNS", "Apache", "MySQL", "Nextcloud", "Prometheus", "Grafana"],
        features: ["Private network with DHCP/DNS", "Secure inter-network routing", "User and access management", "Apache + MySQL web server", "Nextcloud for collaborative storage", "Complete monitoring with automated alerts"],
        competencies: ["OpenStack Administration & Virtualization", "Advanced Network Configuration", "Service Deployment & Management", "Monitoring & Observability"],
        results: ["Complete and functional cloud infrastructure", "Secure private network with integrated services", "Complete monitoring with automated alerts", "Detailed technical documentation"],
        githubUrl: "#"
      },
      {
        title: "IS Security",
        category: "School Project",
        image: "/Portfolio_V3/images/network-security-audit-dashboard-with-vulnerabilit.png",
        description: "Secure enterprise infrastructure design according to ANSSI recommendations.",
        context: "This ambitious project consisted of designing and deploying a complete enterprise infrastructure, scrupulously respecting ANSSI recommendations.",
        objective: "The architecture included a DMZ to isolate public services, a secure internal information system, and multiple protection layers with redundant firewalls.\n\nDefense in Depth:\n‚Ä¢ Multiple security layers: firewalls, IDS/IPS, antivirus\n‚Ä¢ Network segmentation with secure VLANs\n‚Ä¢ Access control and data encryption",
        tags: ["ESXI 6.7", "Cisco", "WatchGuard", "StormShield", "Veeam", "PRTG", "Splunk", "Active Directory", "BIND", "Apache"],
        features: ["DMZ with public web servers", "WatchGuard and StormShield Firewalls", "Active Directory with secure GPOs", "PRTG for network monitoring", "Splunk for log analysis", "Veeam for centralized backup"],
        competencies: ["Enterprise Security Architecture", "Firewall & IDS/IPS Configuration", "Identity & Access Management", "Security Monitoring & Analysis"],
        results: ["Infrastructure compliant with ANSSI recommendations", "Multi-layer security with complete monitoring", "3-2-1 backup strategy operational", "Detailed technical documentation and procedures"],
        githubUrl: "#"
      },
      {
        title: "Pentesting Discovery",
        category: "School Project",
        image: "/Portfolio_V3/images/web-application-penetration-testing-with-burp-suit.png",
        description: "Self-learning project on penetration testing techniques.",
        context: "This self-learning project aimed to acquire the basics of ethical pentesting.",
        objective: "It involved understanding security audit methodologies and mastering essential tools used by cybersecurity professionals. The project included solving a complex technical questionnaire requiring the identification and exploitation of vulnerabilities on various systems in a controlled laboratory environment.",
        tags: ["Kali Linux", "Metasploit", "Nmap", "Hydra", "SQLmap", "Burp Suite", "Wireshark", "John the Ripper"],
        features: ["Reconnaissance and Exploitation (Nmap, Metasploit, Hydra)", "Analysis and Reporting (Burp Suite, SQLmap)", "Privilege escalation on Linux and Windows", "Documentation and remediation recommendations"],
        competencies: ["Ethical Penetration Testing", "Web/Network Vulnerability Analysis", "Advanced Security Tool Usage", "Security Audit Methodologies"],
        results: ["Mastery of essential pentesting tools", "Understanding of common vulnerabilities", "Ability to write technical reports", "Awareness of ethical and legal aspects"],
        githubUrl: "#"
      },
      {
        title: "Data Processing with Python",
        category: "School Project",
        image: "/Portfolio_V3/images/python-data-analysis-dashboard-with-charts--graphs.png",
        description: "Analysis and visualization of calendar data.",
        context: "This project consisted of developing a sophisticated Python script to analyze and process data from calendar files in CSV format.",
        objective: "The goal was to create a tool capable of extracting, filtering, and presenting specific information about events and meetings. The main challenge was to transform raw data into actionable insights, presented in the form of Markdown tables and interactive charts.",
        tags: ["Python", "Pandas", "Matplotlib", "CSV", "Markdown", "HTML/CSS", "Jupyter", "NumPy"],
        features: ["Automatic CSV file parsing", "Intelligent filtering by type and date", "Matplotlib chart generation", "Formatted Markdown tables", "Custom HTML/CSS export"],
        competencies: ["Data Manipulation with Pandas", "Visualization with Matplotlib", "Object-Oriented Python Development", "Unit Testing & Documentation"],
        results: ["Complete and functional data analysis tool", "Clear and informative graphical visualizations", "Documented code with unit tests", "Intuitive and robust user interface"],
        githubUrl: "#"
      }
    ]
  }
};

// Deprecated but kept for compatibility during refactor if needed (mapped to FR default)
export const PROFILE = {
  name: "Math√©o Pinget",
  title: "Ing√©nieur DevOps",
  phone: "06.40.24.07.08",
  email: "matheo.pinget@gmail.com",
  location: "Evian-les-Bains, France",
  avatar: "/Portfolio_V3/images/pp.jpg",
  // Map other fields to TRANSLATIONS.fr for fallback
  tagline: TRANSLATIONS.fr.hero.description,
  about: TRANSLATIONS.fr.about.description,
  credlyUrl: CREDLY_URL,
};

// Kept for backward compat with components not yet updated, but will use SKILLS_DATA from translations
export const SKILLS = SKILLS_DATA;
// Projects and Experience are now dynamic in translations
export const PROJECTS = TRANSLATIONS.fr.projects_data;
export const EXPERIENCE = TRANSLATIONS.fr.experience.data;
export const EDUCATION = TRANSLATIONS.fr.experience.education;
export const PASSIONS = TRANSLATIONS.fr.passions.items;
